#è¿™ä¸ªç”¨äºå¿«é€Ÿä¸‹è½½web of scienceä¸­çš„ä¸€ç³»åˆ—çš„PDF
import os
import re
import time
import random
import requests
from urllib.parse import quote_plus
from concurrent.futures import ThreadPoolExecutor, as_completed
from bs4 import BeautifulSoup

# Sci-Hub é•œåƒ
SCI_HUB_MIRRORS = [
    'https://sci-hub.ren',
    'https://sci-hub.ru',
    'https://sci-hub.st',
    'https://sci-hub.ee',
    'https://sci-hub.se'
]

# ä¸‹è½½ç›®å½•
DOWNLOAD_DIR = r"K:\PDF\SCI-HUB\Web of science"
os.makedirs(DOWNLOAD_DIR, exist_ok=True)

# å¤±è´¥ DOI æ–‡ä»¶
FAIL_FILE = r"K:\PDF\SCI-HUB\Web of science\A_failDOI_google.txt"

# æœ€å¤§çº¿ç¨‹æ•°
MAX_WORKERS = 10

# å…¨å±€å˜é‡ï¼Œè®°å½•å½“å‰æœ€ä¼˜é•œåƒ
best_mirror = None

# ä¸‹è½½è®¡æ•°å™¨
download_count = 0
total_count = 0

def safe_filename(doi):
    """æ›¿æ¢ Windows éæ³•å­—ç¬¦"""
    return re.sub(r'[<>:"/\\|?*]', '_', doi) + '.pdf'

def fetch_pdf_link(doi):
    """ä» Sci-Hub è·å– PDF é“¾æ¥ï¼ˆå…¼å®¹ iframe / embed / objectï¼‰"""
    global best_mirror
    doi_encoded = quote_plus(doi)
    headers = {'User-Agent': 'Mozilla/5.0'}

    # é•œåƒä¼˜å…ˆé¡ºåº
    mirrors = []
    if best_mirror and best_mirror in SCI_HUB_MIRRORS:
        mirrors.append(best_mirror)
    mirrors.extend([m for m in SCI_HUB_MIRRORS if m != best_mirror])

    for base in mirrors:
        try:
            url = f"{base.rstrip('/')}/{doi_encoded}"
            resp = requests.get(url, headers=headers, timeout=20)
            resp.raise_for_status()

            soup = BeautifulSoup(resp.text, 'html.parser')

            pdf_url = None
            # 1. iframe
            iframe = soup.find('iframe')
            if iframe and iframe.get('src'):
                pdf_url = iframe.get('src')

            # 2. embed
            if not pdf_url:
                embed = soup.find('embed')
                if embed and embed.get('src'):
                    pdf_url = embed.get('src')

            # 3. object
            if not pdf_url:
                obj = soup.find('object')
                if obj and obj.get('data'):
                    pdf_url = obj.get('data')

            if not pdf_url:
                continue  # å½“å‰é•œåƒå¤±è´¥

            # å¤„ç†ç›¸å¯¹è·¯å¾„
            if pdf_url.startswith('//'):
                pdf_url = 'https:' + pdf_url
            elif pdf_url.startswith('/'):
                host = url.split('/')[2]
                pdf_url = f'https://{host}{pdf_url}'

            best_mirror = base
            return pdf_url
        except Exception:
            continue
    return None

def download_pdf(doi):
    """ä¸‹è½½å•ä¸ª DOI çš„ PDF"""
    global download_count, total_count

    try:
        pdf_url = fetch_pdf_link(doi)
        download_count += 1  # æ›´æ–°è¿›åº¦

        if not pdf_url:
            with open(FAIL_FILE, 'a', encoding='utf-8') as f:
                f.write(doi + '\n')
            print(f"[{download_count}/{total_count}] {doi} ğŸš« æ‰€æœ‰é•œåƒå¤±è´¥")
            return False

        headers = {'User-Agent': 'Mozilla/5.0'}
        resp = requests.get(pdf_url, headers=headers, stream=True, timeout=30)
        resp.raise_for_status()

        filename = safe_filename(doi)
        path = os.path.join(DOWNLOAD_DIR, filename)
        with open(path, 'wb') as f:
            for chunk in resp.iter_content(8192):
                f.write(chunk)

        print(f"[{download_count}/{total_count}] {doi} âœ… ä¸‹è½½å®Œæˆ: {path}")
        return True
    except Exception as e:
        download_count += 1
        print(f"[{download_count}/{total_count}] {doi} âŒ ä¸‹è½½å¤±è´¥: {e}")
        with open(FAIL_FILE, 'a', encoding='utf-8') as f:
            f.write(doi + '\n')
        return False

def main(dois):
    global total_count
    total_count = len(dois)
    start_time = time.time()

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(download_pdf, doi): doi for doi in dois}
        for future in as_completed(futures):
            doi = futures[future]
            try:
                future.result()
            except Exception as e:
                print(f"[ERR] {doi} çº¿ç¨‹å¼‚å¸¸: {e}")

    elapsed = time.time() - start_time
    print(f"âœ… å…¨éƒ¨å®Œæˆï¼Œç”¨æ—¶ {elapsed:.2f} ç§’")

if __name__ == '__main__':
    doi_file = r'K:\Abstract\DOI\crossref_dois.txt' 
    with open(doi_file, 'r', encoding='utf-8') as f:
        dois = [line.strip() for line in f if line.strip()]
    main(dois)
